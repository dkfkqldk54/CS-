<h1>:green_book: <쉽게 배우는 알고리즘> 정리</h1>

<a href="#1">:pencil2: Chapter1. 알고리즘 설계와 분석의 기초</a>
- O 표기법
- Ω 표기법
- Θ 표기법
- o 표기법
- ω 표기법

<a href="#2">:pencil2: Chapter2. 점화식과 알고리즘 복잡도 분석</a>
- 반복 대치
- 추정 후 증명
- 마스터 정리

<a href="#3">:pencil2: Chapter3. 정렬</a>
- 기본적인 정렬 알고리즘: 선택 정렬
- 기본적인 정렬 알고리즘: 버블 정렬
- 기본적인 정렬 알고리즘: 삽입 정렬
- 고급 정렬 알고리즘: 병합 정렬
- 고급 정렬 알고리즘: 퀵 정렬
- 고급 정렬 알고리즘: 힙 정렬
- 특수 정렬 알고리즘: 기수 정렬
- 특수 정렬 알고리즘: 계수 정렬

<h2><a id="1">:pencil2: Chapter1. 알고리즘 설계와 분석의 기초</a></h2>

**:pushpin: O 표기법**

O(g(n)) = {f(n) | ∃c > 0, n0 > 0 s.t. ∀n >= n0, f(n) <= cg(n)}<br>
O(g(n)) = {f(n) | 모든 n > n0에 대하여 f(n) <= cg(n)인 양의 상수 c와 n0가 존재한다}<br>
O(g(n)) = {f(n) | 충분히 큰 모든 n에 대하여 f(n) <= cg(n)인 양의 상수 c가 존재한다}<br>
<br>
O(g(n))은 충분히 큰 n에 대하여 g(n)에 상수만 곱하면 g(n)이 누를 수 있는 모든 함수의 집합임.<br>
n^2에 3보다 크거나 같은 상수를 곱하면 3n^2을 누를 수 있으므로 3n^2은 O(n^2)에 속함.<br>
<br>
5n^2 = O(n^2)임을 보여라.<br>
c를 6, n0을 1로 잡으면 모든 n >= n0(=1)에 대하여 5n^2 <= 6n^2임. 즉 정의를 만족하는 c와 n0이 존재함.<br>

**:pushpin: Ω 표기법**
  
  Ω(g(n)) = {f(n) | ∃c > 0, n0 > 0 s.t. ∀n >= n0, cg(n) <= f(n)}<br>
  Ω(g(n)) = {f(n) | 모든 n > n0에 대하여 cg(n) <= f(n)인 양의 상수 c와 n0가 존재한다}<br>
  Ω(g(n)) = {f(n) | 충분히 큰 모든 n에 대하여 cg(n) <= f(n)인 양의 상수 c가 존재한다}<br>
  <br>
  Ω(g(n))은 충분히 큰 n에 대하여 g(n)에 상수만 곱하면 g(n)이 압도당할 수 있는 모든 함수의 집함임.<br>
  <br>
  5n^2 = Ω(n^2)임을 보여라.<br>
  c를 4로 잡고, n0 = 1로 잡으면 모든 n >= n0(=1)에 대하여 4n^2 <= 5n^2임. 즉 정의를 만족하는 c와 n0이 존재함.<br>
  
**:pushpin: Θ 표기법**
 
  Θ(g(n)) = O(g(n)) ∩ Ω(g(n))<br>
  Θ(g(n)) = {f(n) | ∃c1, c2 > 0, n0 > 0 s.t. ∀n >= n0, c1g(n) <= f(n) <= c2g(n)}<br>
  Θ(g(n)) = {f(n) | 충분히 큰 모든 n에 대하여 c1g(n) <= f(n) <= c2g(n)인 양의 상수 c1, c2가 존재한다.}<br>
  <br>
  5n^2 = Θ(n^2)임을 보여라.<br>
  5n^2 = O(n^2), 5n^2 = Ω(n^2)임을 보였기 때문에 5n^2 = Θ(n^2)이다.<br>

**:pushpin: o 표기법**
  
  함수의 증가율이 점근적 의미에서 어느 한계보다 더 작다는 것을 표현하고자 할 때 사용됨.<br>
  예를 들어 함수 5n = o(n^2)이다. 5n의 증가율은 n^2의 증가율보다 작기 때문이다.<br>
  그렇지만 함수 (1/2) * n^2은 o(n^2)에 속하지 않음. (1/2) * n^2의 증가 속도가 n^2의 증가 속도와 점근적으로 동일하기 때문임.<br>
  <br>
  o(g(n)) = {f(n) | lim f(n) / g(n) = 0 }<br>
  o(g(n)) = {f(n) | ∃n0 > 0 s.t. ∀c>0 and n>=n0, f(n) < cg(n)}<br>
  o(g(n)) = {f(n) | n이 충분히 크면 모든 c>0에 대하여 f(n) < cg(n)이다.}<br>
  o(g(n))은 충분히 큰 n에 대하여 g(n)에 아무리 작은 상수를 곱해도 g(n)이 압도하는 모든 함수의 집합임.<br>
  <br>
  5n^2 = o(n^3)임을 보여라.<br>
  lim (n^2 -5) / n^3 = 0임.<br>
  
**:pushpin: ω 표기법**
  
  함수의 증가율이 점근적 의미에서 어느 한계보다 더 크다는 것을 표현하고자 할 때 사용함.<br>
  예를 들어 5n^3 = ω(n^2)임. 5n^3의 증가 속도는 n^2의 증가 속도보다 큼.<br>
  함수 2n^2은 ω(n^2)에 속하지 않음. 2n^2의 증가 속도는 n^2의 증가 속도와 점근적으로 동일하기 때문임.<br>
  ω표기는 함수의 기울기상의 여유 있는 하한을 나타냄.<br>
  <br>
  ω(g(n)) = {f(n) | lim f(n) / g(n) = ∞}<br>
  ω(g(n)) = {f(n) | ∃n0 > 0 s.t. ∀c>0 and n>=n0, cg(n) < f(n)}<br>
  ω(g(n)) = {f(n) | n이 충분히 크면 모든 c > 0에 대하여 cg(n) < f(n)이다.}<br>
  <br>
  n^3 / 4 = ω(n^2)임을 보여라.<br>
  lim ( (n^3 /4) / n^2 ) = ∞이므로 n^3 / 4 = ω(n^2)이다.<br>

<h2><a id="2">:pencil2: Chapter2. 점화식과 알고리즘 복잡도 분석</a></h2>


점화식은 어떤 함수를 자신과 똑같은 함수를 이용해 나타내는 것임.<br>
n!의 점화식은 f(n) = n * f(n-1), 피보나치 수열의 점화식은 f(n) = f(n-1) + f(n-2)임.<br>

**:pushpin: 반복 대치**

<pre>
factorial(n)
{
  1. if (n = 1) return 1;
  2. return n * factorial(n-1);
}
</pre>

이 알고리즘으로 n!을 구하는데 걸리는 시간을 T(n)이라고 하면, T(n) = T(n-1) + c임.<br>
c는 자기호출을 제외한 나머지의 수행 시간으로 1을 수행하는 시간과 2의 곱셈을 한번 수행하는 시간임.<br>
크기가 1이면 T(1) <= c임.<br>

<pre>
T(n) = T(n-1) + c
     = T(n-2) + 2c
     ...
     = T(1) + (n-1)c
     <= cn
</pre>

T(n) <= cn이므로 T(n) = O(n)이다.<br>

**병합 정렬**<br>

입력의 크기가 n인 배열을 정렬하는 병합 정렬은 배열을 이등분한 다음, 각각을 재귀적으로 병합 정렬해 이 둘을 병합함으로써 정렬을 끝냄.<br>
입력의 크기가 n인 배열에 대한 병합 정렬에서 대소 비교의 총 횟수를 T(n)이라고 하자.<br>
n = 2^k이라고 가정해도 일반성을 잃지 않으므로 n = 2^k으로 가정하겠음.<br>
T(n) <= 2T(n/2) + n임.<br>
n은 merge(A, p, q, r)에 필요한 최대 비교 횟수 n-1과 if (p<r) then에 있는 비교 한 번을 합한 것임.<br>

<pre>
T(n) <= 2T(n/2) + n
     <= 2^2T(n/2^2) + 2n
     ...
     <= 2^kT(n/2^k) + kn
     = nT(1) + nlogn
     = n + nlogn
      = O(nlogn)
</pre>

T(n) <= 2T(n/2) + n을 T(n) <= 2T(n/2) + O(n)으로 표시하기도 함.<br>
여기서 O(n)은 집합으로서 O(n)을 의미하지 않고, O(n)에 속하는 함수 하나를 대신하는 관행적 표현임.<br>

**n = 2^k**<br>

점근적 복잡도의 계산을 용이하게 하기 위해 n = 2^k이라는 가정을 종종 사용함.<br>
어떠한 n이라도 n과 2n 사이에 2의 멱수가 하나 있음.<br>
즉, n <= 2^k <= 2n인 2^k가 하나 존재함.<br>
임의의 상수 r에 대해 T(n) = O(n^r)이라면 T(2n) = O(2^r * n^r) = O(n^r)이므로 T(n) = T(2n)임.<br>
T(n) <= T(2^k) <= T(2n)이고 T(n) = T(2n) 이므로 T(n) = T(2^k) = T(2n)임.<br>
즉, n의 오른쪽에서 처음으로 마나는 2의 멱수에 대한 함수도 항상 n에 대한 함수와 같은 점근적 복잡도를 가지므로 n = 2^k로 가정해도 점근적 분석의 결과는 같음.<br>

**:pushpin: 추정 후 증명**

추정 후 증명은 식의 모양을 보고 점근적 복잡도를 추정한 다음 그것이 옳음을 귀납적으로 증명하는 방법임.<br>

<pre>
T(n) <= 2T(n/2) + n의 점근적 복잡도는 T(n) = O(nlogn)이다. 즉 충분히 큰 n에 대하여 T(n) <= cnlogn인 양의 상수 c가 존재한다.

경계조건: T(2) <= c2log2를 만족하는 c가 존재한다.

귀납적 가정과 전개: n/2에 대해 T(n/2) <= c(n/2)log(n/2)을 만족한다고 가정하면,
T(n) <= 2T(n/2) + n
     <= 2c(n/2)log(n/2) + n
     = cnlogn - cnlog2 +n
     <= cnlogn
     
이를 만족하는 상수 c가 존재한다. 따라서 T(n) = O(nlogn)이다.
</pre>

여기서 log1 = 0이므로 T(1) <= 1log1은 불가능하기 때문에 T(2)를 경계조건으로 잡은 것임.<br>
경계조건으로 T(2)가 아닌 훨씬 큰 상수 a에 대해 T(a) <= caloga임을 보여도 상관없음.<br>
일반적으로  T(n) = f(n)임을 보이기 위해 상수 a를 경계치로 잡으면 T(a)도 상수가 되므로 f(n)이 양수인 한 T(a) <= cf(a)를 만족시키는 c가 항상 존재함.<br>
그러므로 경계조건을 만족시키는 경계치는 항상 잡을 수 있기 때문에 경계조건을 확인하지 않아도 됨.<br>

<pre>
T(n) <= 2T(n/2 + 10) + n의 점근적 복잡도는 T(n) = O(nlogn)이다. 즉, 충분히 큰 n에 대하여 T(n) <= cnlogn인 양의 상수 c가 존재한다.

증명

T(n) <= 2T(n/2 + 10) + n
     <= 2c(n/2 + 10)log(n/2 + 10) + n
     = cnlog(n/2 + 10) + 20clog(n/2 + 10) + n
     <= cnlog(3n / 4) + 20clog(3n / 4) + n
     = cnlogn + cn(log3 - log4) + 20clog(3n / 4) + n
     <= cnlogn
     
이를 만족하는 상수 c가 존재한다. 따라서 T(n) = O(nlogn)이다.
이 때, n에 대한 제약이 있다.
n/2 + 10 < n이어야 하므로 n > 20이어야 논리적인 전개가 가능하다.
식을 간단하게 하기 위해서 n/2 + 10 <= 3n /4임을 가정했는데 이는 n >= 40이어야 가능하다.
</pre>

cn(log3 - log4) + 20clog(3n / 4) + n이 음수가 되어야 하는데, c(log3 - log4) + 1을 충분히 작은 음수로 만들 수 있으면 20clog(3n/4)이 n에 대한 차수가 낮아 압도할 수 있음.<br>

**주의**<br>
<pre>
T(n) <= 2T(n/2) + n의 점근적 복잡도가 T(n) = O(n)이라고 가정하고, 충분히 큰 n에 대하여 T(n) <= cn인 양의 상수 c가 존재한다는 것을 증명하려 할 때
T(n) <= 2T(n/2) + n
     <= 2c(n/2) + n
     = cn + n
     = c'n
     = O(n)
</pre>
c' = c + 1이라는 추가적은 상수를 만들어서 c'n <= cn이라고 주장하면 안 됨.<br>
처음에 쓴 c와 나중에 쓰는 c는 같은 상수여야 함.<br>

<pre>
T(n) <= 2T(n/2) + n
     <= 2c(n/2) + n
     = cn + n
     = O(n)
</pre>
n(c+1) = O(n)인건 맞지만 T(n) <= cn + n <= cn임을 증명하지 못 했음.<br>
따라서 귀납적 증명이 완결되지 않았으므로 틀렸음.<br>

<pre>
T(n) = 2T(n/2) + 1의 점근적 복잡도는 O(n)이다.

실패하는 증명

충분히 큰 n에 대해 T(n) <= cn인 양의 상수 c가 존재한다는 것을 증명하려 한다.
T(n) = 2T(n/2)  + 1
     <= 2c(n/2) + 1
     <= cn + 1
여기서 cn + 1 < cn임을 입증할 수 없음.

성공하는 증명

T(n) <= cn임을 증명하는 대신 T(n) <= cn - 2임을 증명할 수 있어도 T(n) = O(n)임.<br>
T(n) = 2T(n/2) + 1
     <= 2(cn/2 - 2) + 1
     = cn -3
     <= cn
</pre>

추정 후 증명법이 유용하게 사용되려면 우선 추정을 의미있게 해야 함.<br>
너무 여유롭게 추정해 증명하는 것은 별로 의미가 없음.<br>

**추가: 경계조건**<br>

재귀적으로 정의된 함수나 수열은 자신의 값을 계산하기 위해 자신과 같은 함수나 수열을 더 작은 입력값으로 호출하는 경우가 많음.<br>
이러한 호출은 일반적으로 입력값이 충분히 작아지거나 특정 조건을 만족할 때까지 반복됨.<br>
이 때, 함수나 수열이 호출되는 과정에서 더 이상 호출하지 않고 종료될 때, 이를 '경계조건' 혹은 '종료조건'이라고 부름.<br>
예를 들어, 피보나치 수열은 아래와 같은 점화식으로 정의됨.<br>
<pre>
F(0) = 0
F(1) = 1
F(n) = F(n-1) + F(n-2) (n >= 2)
</pre>
이 때, F(0)와 F(1)은 경계조건으로 사용됨.<br>
F(0)와 F(1)을 미리 정의함으로써, F(n)을 계산하기 위한 종료 조건으로 사용할 수 있음.<br>

**:pushpin: 마스터 정리**

<pre>
T(n) = aT(n/b) + f(n)
</pre>

마스터 정리는 특정한 모양을 가진 재귀식에서 바로 결과를 알 수 있는 유용한 정리임.<br>
입력의 크기가 n인 문제를 풀기 위해 입력의 크기가 n/b인 문제를 a개 풀고, 나머지 f(n)의 오버헤드가 필요한 알고리즘들이 해당됨.<br>
a >= 1, b >= 1에 대해 T(n) = aT(n/b) + f(n)인 점화식에서, h(n) = n^(logb(a))라고 할 때 T(n)의 점근적 복잡도는 다음과 같음.<br>
<pre>
어떤 양의 상수 ε에 대하여 f(n) / h(n) = O(1/n^ε)이면, T(n) = θ(h(n))이다.
어떤 양의 상수 ε에 대하여 f(n) / h(n) = Ω(n^ε)이고, 어떤 상수 c(<1)와 충분히 큰 모든 n에 대해 af(n/b) <= cf(n)이면 T(n) = θ(f(n))이다. 
f(n) / h(n) = θ(1)이면 T(n) = θ(h(n)logn)이다.
</pre>

마스터 정리의 근사 버전은 아래와 같음.
<pre>
lim f(n) / h(n) = 0이면 T(n) = θ(h(n))이다.
lim f(n) / h(n) = ∞이고, 충분히 큰 모든 n에 대해 af(n/b) < f(n)이면 T(n) = θ(f(n))이다.
f(n) / h(n) = θ(1)이면 T(n) = θ(h(n)logn)이다.
</pre>

마스터 정리의 근사 버전은 원형과 정확히 같지는 않음.<br>
lim f(n) / h(n) = ∞은 h(n)이 f(n)을 압도한다는 뜻이고, f(n) / h(n) = O(1/n^ε)은 h(n)이 f(n)을 적어도 다항식의 비율로 압도한다는 뜻임.<br>
lim f(n) / h(n) = lim 1 / logn의 경우에는 lim f(n) / h(n) = 0이지만 logn의 비율로 압도할 뿐 다항식의 비율로 압도하지는 않음.<br>
즉. f(n) / h(n) = O(1/n^ε)은 성립하지 않음.<br>
lim f(n) / h(n) = ∞와 f(n) / h(n) = Ω(n^ε) 사이에도 다항식 비율에 관한 차이가 있음.<br>
충분히 큰 모든 n에 대해 af(n/b) < f(n)과 어떤 상수 c(<1)와 충분히 큰 모든 n에 대해 af(n/b) <= cf(n)도 고정 비율 c이하의 보장이라는 미묘한 차이가 있지만 반례를 찾기가 극히 힘들기 때문에 사실상 이 둘을 구분 없이 사용해도 무방함.<br>

<pre>
T(n) = 2T(n/3) + c (c는 상수)

a = 2, b =  3, f(n) = c, h(n) = n^log3(2)
lim f(n) / h(n) = 0이므로 T(n) = θ(n^log3(2))이다.
</pre>

<pre>
T(n) = 2T(n/4) + n

a = 2, b = 4, f(n) = n, h(n) = n^log4(2)
lim f(n) / h(n) = ∞이고 af(n/b) = 2(n/4) = n/2 < n임.
또한 n/2 <= (1/2)f(n)이므로 c = 1/2에 대해 af(n/b) <= cf(n)을 만족함.
따라서 T(n) = θ(nlogn)임.
</pre>

<pre>
T(n) = 2T(n/2) + n

a = 2, b = 2, f(n) = n, h(n) = n
f(n) / h(n) = 1이므로 T(n) = θ(nlogn)임.
</pre>

마스터 정리를 쓸 수 없는 모양인 점화식의 변수를 치환함으로써 마스터 정리를 쓸 수 있는 모양으로 변형하는 방법도 있음.<br>

<pre>
T(n) = 2T(n^(1/2)) + logn

m = log2(n)으로 놓으면

T(2^m) = 2T(2^(m/2)) + m

이는 아래와 같이 다시 표현할 수 있음.

S(m) = 2S(m/2) + m

a = 2, b = 2, f(m) = m, h(m) = m이므로
S(m) = θ(mlogm) = θ(logn loglogn)임.
</pre>

마스터 정리에서 f(n)은 크기가 n인 문제(최상위 레벨)에서 발생하는 자기 호출 이외의 오버헤드로 크기가 다른 문제들 간의 관계를 반영하는 비용임.<br>
h(n)은 반복적인 자기호출 끝에 마지막으로 크기 1인 문제를 만나는 횟수임.<br>
자기호출 때문에 부담이 더 커지면 수행 시간은 h(n)이 결정하고, 관계를 반영하는 오버헤드가 더 커지면 f(n)이 결정함.<br>
단 f(n)은 상위 레벨의 오버헤드만 의미하므로 하위 레벨에서 발생하는 오버헤드는 반영하고 있지 않음.<br>
af(n/b) <= cf(n)은 자기호출로 만나는 하위레벨의 문제들에서 발생하는 자기호출 이외의 오버헤드들의 총합이 레벨이 내려가면서 적어도 감소해야 한다는 것을 의미함.<br>

<h2><a id="3">:pencil2: Chapter3. 정렬</a></h2>

**:pushpin: 기본적인 정렬 알고리즘: 선택 정렬**

우선 배열 A[1, ..., n]에서 가장 큰 원소를 찾아 이 원소와 배열의 끝자리에 있는 A[n]과 자리를 바꿈.<br>
그러면 방금 맨 뒷자리로 옮긴 원소, 즉 가장 큰 원소는 자기 자리를 찾았으므로 더 이상 신경 쓰지 않아도 됨.<br>
이 원소는 정렬이 끝났다고 볼 수 있으므로 이제 이 원소를 제외한 나머지 원소들로 같은 작업을 반복함.<br>

<pre>
간략한 기술

selectionSort(A[], n)
{
  for last <- n downto 2 {
    A[1, ..., last]중 가장 큰 수 A[k]를 찾는다;
    A[k] <-> A[last];
  }
}
</pre>

<pre>
기호적 기술
selectionSort(A[], n)
{
  for last <- n downto 2 {
    k <- theLargest(A, last);
    A[k] <-> A[last];
  }
}

theLargest(A[], last)
{
  largeset <- 1;
  for i <- 2 to last
    if (A[i] > A[largest]) then largest <- i;
  return largest;
}
</pre>

이 알고리즘에서 입력은 배열 A[1, ..., n]임.<br>
변수 last는 정렬할 배열의 맨 마지막 인덱스, 즉 배열의 크기를 나타냄.<br>
처음에는 배열의 크기가 n으로 시작하므로, A[1, ..., n]을 정렬 대상으로 삼음.<br>
가장 큰 수를 찾아 제자리에 놓을 때마다 last는 1씩 줄어들음.<br>
선택 정렬의 수행 시간은 모든 경우에 Θ(n^2)임.<br>
배열의 크기가 n일 때 n-1번 비교, ... , 배열의 크기가 2일 때 1번 비교함.<br>
따라서 1 + ... + n-1 = n(n-1) / 2임.<br>
수를 비교하는 횟수가 전체 시간을 좌우하므로 이것을 기준으로 수행 시간을 계산함.<br>

**:pushpin: 기본적인 정렬 알고리즘: 버블 정렬**

<pre>
간략한 기술

bubbleSort(A[], n)
{
  for last <- n downto 2
    for i <- 1 to last-1
      if (A[i] > A[i+1]) then A[i] <-> A[i+1];
}
</pre>

버블 정렬의 총 순환 횟수는 (n-1) + (n-2) + ... + 2 + 1 = n(n-1) / 2임.<br>
따라서 수행 시간은 Θ(n^2)임.<br>
버블 정렬 알고리즘은 중간에 배열이 이미 정렬이 되어 있는 상태라도 계속 끝까지 무의미한 순환을 계속함.

<pre>
수정된 bubble sort

bubbleSort(A[], n)
{
  for last <- n downto 2
      sorted <- TRUE;
    for i <- 1 to last-1 {
      if (A[i] > A[i+1]) {
        A[i] <-> A[i+1];
        sorted <- FALSE;
      }
    }
    if (sorted = TRUE) then return;
}
</pre>

**:pushpin: 기본적인 정렬 알고리즘: 삽입 정렬**

삽입 정렬은 이미 정렬되어 있는 i개짜리 배열에 하나의 원소를 더 더하여 정렬된 i+1개짜리 배열을 만드는 과정을 반복함.<br>
한 개짜리 배열에서 시작하여 그 크기를 하나씩 늘리는 정렬임.<br>

<pre>
insertionSort(A[], n)
{
  for i <- 2 to n
    A[1, ..., i]의 적합한 자리에 A[i]를 삽입한다.
}
</pre>

for 루프는 문제의 크기를 하나씩 키워나가는 역할을 함.<br>
A[i]에 관심을 두는 시점에는 A[1, ..., i-1]은 항상 정렬이 되어 있음.<br>
A[i]가 A[i-1]보다 크면 앞에 있는 모든 원소보다 크므로 A[i]는 그냥 제자리에 두면 됨.<br>
그렇지 않으면 A[i-1]부터 시작해서 왼쪽으로 차례로 훑으면서 A[i]가 들어갈 자리를 찾음.<br>
A[i]가 들어가는 자리부터 시작해서 이후의 원소들은 한 칸씩 오른쪽으로 밀려남.<br>

<pre>
insertionSort(A[], n)
{
  for i <- 2 to n {
    loc <- i - 1;
    newItem <- A[i]
    
    while (loc >= 1 and newItem < A[loc]) {
      A[loc + 1] = A[loc];
      loc--;
    }
    A[loc + 1] <- newItem;
  }
}
</pre>

for 루프는 n-1번 순환함.<br>
매 for 루프에서 while은 최대 i-1번 순환함.<br>
가장 운이 좋으면 while 문은 돌아가지 않음.<br>
최악의 경우 수행 시간은 (n-1) + (n-2) + ... + 2 + 1 = n(n-1)/2임.<br>
따라서 Θ(n^2)임.<br>
보통은 대략 A[1, ..., i-1]에서 평균적으로 절반 정도를 훑고 끝낼 것임.<br>
그러므로 전체 비교 횟수는 최악의 경우에 비해 절반 정도 될 것임.<br>
그래도 시간복잡도는 Θ(n^2)임.<br>
<br>
삽입 정렬은 거의 정렬되어 있는 상태로 입력되는 경우에는 가장 매력적인 알고리즘임.<br>
배열이 완전히 정렬된 채로 입력되면 while 루프는 한 번도 수행되지 않고, for 루프는 한번 순환할 때마다 상수 시간이 소요됨.<br>
for 루프는 n-1번 순환되므로 Θ(n)에 가까운 시간이 듬.<br>
배열이 거의 정렬되어 있을 때도 삽입이 매우 수월해져 Θ(n)에 가까운 시간이 듬.<br>
버블 정렬은 배열이 이미 정렬되어 있는 경우에 무의미한 순환을 줄이기 위해 방법이 있긴 했지만 오버헤드가 생김.<br>
삽입 정렬은 별도 장치가 없어도 효율적으로 끝남.<br>
따라서 상황에 따라 가끔 삽입 정렬을 섞어서 씀.<br>
<br>
선택 정렬과 버블 정렬이 n개짜리 배열에서 시작하여 아직 정렬되지 않은 배열의 크기를 하나씩 줄이는 데 반하여, 삽입 정렬은 1개짜리 배열에서 시작하여 이미 정렬된 배열의 크기를 하나씩 늘리는 정렬임.<br>
삽입 정렬에는 수학적 귀납법의 원리가 들어가 있음.<br>
배열의 크기가 1일 때는 성립함.(이미 정렬되어 있으므로)<br>
배열의 크기가 k일 때 성립하면(정렬되어 있으면), 적절한 삽입으로 크기가 k+1일 때도 성립함(정렬됨).<br>
이것으로 삽입 정렬은 올바르게 정렬을 한다는 것이 귀납적으로 증명됨.<br>


**:pushpin: 고급 정렬 알고리즘: 병합 정렬**

**:pushpin: 고급 정렬 알고리즘: 퀵 정렬**

**:pushpin: 고급 정렬 알고리즘: 힙 정렬**

**:pushpin: 특수 정렬 알고리즘: 기수 정렬**

**:pushpin: 특수 정렬 알고리즘: 계수 정렬**
